{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "G3KCGZRIuxOj",
        "621fHRwsvWRE",
        "31tTx_F4vYSV",
        "xqNWJeOt15af",
        "uDeC5XPVul8l",
        "movIhlKH6C9M"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOquNAov5g8gmGC9bCusiPE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MrEminent42/wordle-ai/blob/Nov-2022/WordleAI_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## WordleGame"
      ],
      "metadata": {
        "id": "G3KCGZRIuxOj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4USCxi7juG70"
      },
      "outputs": [],
      "source": [
        "from enum import IntEnum\n",
        "from termcolor import colored\n",
        "\n",
        "def debug(*info):\n",
        "  p = False\n",
        "  if p: print(info)\n",
        "\n",
        "class WordleGame:\n",
        "    def __init__(self, answer):\n",
        "        self.answer = answer.upper()\n",
        "        self.board = []\n",
        "        self.is_over = False\n",
        "        self.win = False\n",
        "\n",
        "    def __repr__(self):\n",
        "        s = \"\"\n",
        "        # in each line\n",
        "        for i, line in enumerate(self.board):\n",
        "            colors = self.get_colors(self.get_line_string(i))\n",
        "            for i, tile in enumerate(line):\n",
        "                # for i, char in enumerate(line):\n",
        "                s += (\n",
        "                    colored(tile.char, \"white\")\n",
        "                    if tile.color == Color.GREY\n",
        "                    else (\n",
        "                        colored(tile.char, \"magenta\")\n",
        "                        if tile.color == Color.YELLOW\n",
        "                        else colored(tile.char, \"green\")\n",
        "                    )\n",
        "                )\n",
        "            s += \"\\n\"\n",
        "\n",
        "        return s\n",
        "\n",
        "    def guess(self, guess):\n",
        "        \"\"\"Takes a five-letter guess, records this guess on the game's board.\n",
        "        Returns the array of Colors with each index corresponding to the color of the letter at that index in the guess\"\"\"\n",
        "        tiles = []\n",
        "        if len(guess) != 5:\n",
        "            raise ValueError(\n",
        "                'Wordle guess must be a 5-letter word. Could not guess with word \"'\n",
        "                + guess\n",
        "                + '\".'\n",
        "            )\n",
        "        # convert everything to upper case\n",
        "        guess = guess.upper()\n",
        "        # debug print\n",
        "        debug(\"Your guess:\", guess)\n",
        "        debug(\"The answer:\", self.answer)\n",
        "        colors = self.get_colors(guess)\n",
        "        # log guess to board\n",
        "        tiles = [Tile(guess[i], colors[i]) for i in range(5)]\n",
        "        self.board.append(tiles)\n",
        "\n",
        "        # check for game over\n",
        "        if len(self.board) >= 6:\n",
        "            self.is_over = True\n",
        "        elif guess == self.answer:\n",
        "            self.is_over = self.win = True\n",
        "\n",
        "        # give back list of colors\n",
        "        return colors\n",
        "\n",
        "    def get_colors(self, guess):\n",
        "        \"\"\"Takes in a five-letter guess, returns an array of Colors with\n",
        "        each index corresponding to the color of the letter at that index in the guess.\"\"\"\n",
        "        if len(guess) != 5:\n",
        "            raise ValueError(\n",
        "                'Can only find colors for words of length 5. Could not find colors for word \"'\n",
        "                + guess\n",
        "                + '\"'\n",
        "            )\n",
        "        colors = []\n",
        "        # occurrences_left = {char: self.answer.count(char) for char in self.answer}\n",
        "        occurrences_left = {}\n",
        "        # more efficient way of counting num occurences\n",
        "        for char in self.answer:\n",
        "            if char in occurrences_left:\n",
        "                occurrences_left[char] += 1\n",
        "            else:\n",
        "                occurrences_left[char] = 1\n",
        "\n",
        "        for i, char in enumerate(guess):\n",
        "            # if the character is in the correct place, green\n",
        "            if self.answer[i] == char:\n",
        "                colors.append(Color.GREEN)\n",
        "                occurrences_left[char] -= 1\n",
        "                debug(\"Green:\", char)\n",
        "            # if the character is in the word, but in the wrong place\n",
        "            elif char in self.answer:\n",
        "                # if there are stil occurences of this char that have not been accounted for\n",
        "                if occurrences_left[char] > 0:\n",
        "                    # append a yellow tile\n",
        "                    colors.append(Color.YELLOW)\n",
        "                    debug(\"Yellow:\", char)\n",
        "                    # record that we have accounted for this occurence\n",
        "                    occurrences_left[char] -= 1\n",
        "                else:\n",
        "                    colors.append(Color.GREY)\n",
        "                    debug(\"Grey:\", char)\n",
        "            else:\n",
        "                colors.append(Color.GREY)\n",
        "                debug(\"Grey:\", char)\n",
        "\n",
        "        return colors\n",
        "\n",
        "    def get_line_string(self, i):\n",
        "        s = \"\"\n",
        "        for tile in self.board[i]:\n",
        "            s += tile.char\n",
        "        return s\n",
        "\n",
        "    def is_over(self):\n",
        "        return self.is_over\n",
        "\n",
        "    def run_game(self):\n",
        "        print(\"Welcome to Wordle-AI!\")\n",
        "        while not self.is_over:\n",
        "            self.guess(input(\"Guess: \"))\n",
        "            print(self)\n",
        "        if self.win:\n",
        "            print(\"Congrats! You found the word in \" + str(len(self.board)) + \" tries.\")\n",
        "        else:\n",
        "            print(\"Darn! You didn't find the word. It was \" + self.answer + \".\")\n",
        "\n",
        "\n",
        "class Color(IntEnum):\n",
        "    GREY = GRAY = 0\n",
        "    YELLOW = 1\n",
        "    GREEN = 2\n",
        "\n",
        "\n",
        "class Tile:\n",
        "    def __init__(self, character, color):\n",
        "        self.char = character\n",
        "        self.color = color"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DQN\n",
        "Based on https://www.tensorflow.org/agents/tutorials/1_dqn_tutorial"
      ],
      "metadata": {
        "id": "akUNya1tu1KR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TF Setup"
      ],
      "metadata": {
        "id": "621fHRwsvWRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get install -y xvfb ffmpeg freeglut3-dev\n",
        "!pip install 'imageio==2.4.0'\n",
        "!pip install pyvirtualdisplay\n",
        "!pip install tf-agents[reverb]\n",
        "!pip install pyglet"
      ],
      "metadata": {
        "id": "pgZjknCBuXvG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28b2db89-7bf1-418c-9616-9b38a87b0d7b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r                                                   \rHit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "\r                                                   \r0% [1 InRelease gpgv 88.7 kB]\r                             \r0% [Working]\r0% [3 InRelease gpgv 242 kB] [Waiting for headers]\r                                                  \rGet:13 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,561 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [1,259 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [3,067 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,338 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,493 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [1,300 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-backports/main amd64 Packages [64.0 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [20.5 kB]\n",
            "Fetched 13.4 MB in 5s (2,798 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:3.4.11-0ubuntu0.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  freeglut3 freeglut3-dev xvfb\n",
            "0 upgraded, 3 newly installed, 0 to remove and 7 not upgraded.\n",
            "Need to get 982 kB of archives.\n",
            "After this operation, 3,350 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 freeglut3 amd64 2.8.1-3 [73.6 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 freeglut3-dev amd64 2.8.1-3 [124 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.11 [785 kB]\n",
            "Fetched 982 kB in 1s (1,132 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package freeglut3:amd64.\n",
            "(Reading database ... 123991 files and directories currently installed.)\n",
            "Preparing to unpack .../freeglut3_2.8.1-3_amd64.deb ...\n",
            "Unpacking freeglut3:amd64 (2.8.1-3) ...\n",
            "Selecting previously unselected package freeglut3-dev:amd64.\n",
            "Preparing to unpack .../freeglut3-dev_2.8.1-3_amd64.deb ...\n",
            "Unpacking freeglut3-dev:amd64 (2.8.1-3) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.11_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.11) ...\n",
            "Setting up freeglut3:amd64 (2.8.1-3) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.11) ...\n",
            "Setting up freeglut3-dev:amd64 (2.8.1-3) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.6) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting imageio==2.4.0\n",
            "  Downloading imageio-2.4.0.tar.gz (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from imageio==2.4.0) (1.21.6)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio==2.4.0) (7.1.2)\n",
            "Building wheels for collected packages: imageio\n",
            "  Building wheel for imageio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imageio: filename=imageio-2.4.0-py3-none-any.whl size=3303897 sha256=b9c45c7571bd21d2304e6aebe14836d031be7d5a1a12f530f525b29ca1242780\n",
            "  Stored in directory: /root/.cache/pip/wheels/aa/de/2f/6c5a75120d68a2c3138120c8d0ce1c6f9483a4b96307986bf2\n",
            "Successfully built imageio\n",
            "Installing collected packages: imageio\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: imageio 2.9.0\n",
            "    Uninstalling imageio-2.9.0:\n",
            "      Successfully uninstalled imageio-2.9.0\n",
            "Successfully installed imageio-2.4.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: pyvirtualdisplay\n",
            "Successfully installed pyvirtualdisplay-3.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tf-agents[reverb]\n",
            "  Downloading tf_agents-0.14.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 5.4 MB/s \n",
            "\u001b[?25hCollecting pygame==2.1.0\n",
            "  Downloading pygame-2.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 18.3 MB 85 kB/s \n",
            "\u001b[?25hCollecting gym<=0.23.0,>=0.17.0\n",
            "  Downloading gym-0.23.0.tar.gz (624 kB)\n",
            "\u001b[K     |████████████████████████████████| 624 kB 57.5 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (1.15.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (7.1.2)\n",
            "Requirement already satisfied: protobuf>=3.11.3 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (3.19.6)\n",
            "Requirement already satisfied: gin-config>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (0.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (4.1.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (1.21.6)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (1.14.1)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (1.5.0)\n",
            "Requirement already satisfied: absl-py>=0.6.1 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (1.3.0)\n",
            "Requirement already satisfied: tensorflow-probability==0.17.0 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (0.17.0)\n",
            "Collecting dm-reverb~=0.9.0\n",
            "  Downloading dm_reverb-0.9.0-cp37-cp37m-manylinux2014_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 4.6 MB/s \n",
            "\u001b[?25hCollecting tensorflow~=2.10.0\n",
            "  Downloading tensorflow-2.10.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 578.1 MB 23 kB/s \n",
            "\u001b[?25hCollecting rlds\n",
            "  Downloading rlds-0.1.6-py3-none-manylinux2010_x86_64.whl (45 kB)\n",
            "\u001b[K     |████████████████████████████████| 45 kB 2.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability==0.17.0->tf-agents[reverb]) (0.4.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability==0.17.0->tf-agents[reverb]) (4.4.2)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability==0.17.0->tf-agents[reverb]) (0.1.7)\n",
            "Requirement already satisfied: portpicker in /usr/local/lib/python3.7/dist-packages (from dm-reverb~=0.9.0->tf-agents[reverb]) (1.3.9)\n",
            "Requirement already satisfied: importlib-metadata>=4.10.0 in /usr/local/lib/python3.7/dist-packages (from gym<=0.23.0,>=0.17.0->tf-agents[reverb]) (4.13.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from gym<=0.23.0,>=0.17.0->tf-agents[reverb]) (0.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.10.0->gym<=0.23.0,>=0.17.0->tf-agents[reverb]) (3.10.0)\n",
            "Collecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-22.10.26-py2.py3-none-any.whl (26 kB)\n",
            "Collecting tensorflow-estimator<2.11,>=2.10.0\n",
            "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[K     |████████████████████████████████| 438 kB 69.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-agents[reverb]) (1.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-agents[reverb]) (21.3)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-agents[reverb]) (14.0.6)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-agents[reverb]) (2.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-agents[reverb]) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-agents[reverb]) (1.50.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-agents[reverb]) (3.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-agents[reverb]) (3.3.0)\n",
            "Collecting tensorboard<2.11,>=2.10\n",
            "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9 MB 34.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-agents[reverb]) (57.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-agents[reverb]) (0.27.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-agents[reverb]) (1.6.3)\n",
            "Collecting keras<2.11,>=2.10.0\n",
            "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 43.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow~=2.10.0->tf-agents[reverb]) (0.38.4)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow~=2.10.0->tf-agents[reverb]) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-agents[reverb]) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-agents[reverb]) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-agents[reverb]) (2.14.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-agents[reverb]) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-agents[reverb]) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-agents[reverb]) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-agents[reverb]) (0.6.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-agents[reverb]) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-agents[reverb]) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-agents[reverb]) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-agents[reverb]) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-agents[reverb]) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-agents[reverb]) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-agents[reverb]) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-agents[reverb]) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-agents[reverb]) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-agents[reverb]) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow~=2.10.0->tf-agents[reverb]) (3.0.9)\n",
            "Building wheels for collected packages: gym\n",
            "  Building wheel for gym (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.23.0-py3-none-any.whl size=697663 sha256=ada4a77d6d5e6636fd9e7bdf44be1c6df5b98d021cece1e619c037bb78d27a95\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/7e/16/4d727df048fdb96518ec5c02266e55b98bc398837353852a6a\n",
            "Successfully built gym\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, pygame, keras, gym, flatbuffers, tf-agents, tensorflow, rlds, dm-reverb\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "Successfully installed dm-reverb-0.9.0 flatbuffers-22.10.26 gym-0.23.0 keras-2.10.0 pygame-2.1.0 rlds-0.1.6 tensorboard-2.10.1 tensorflow-2.10.1 tensorflow-estimator-2.10.0 tf-agents-0.14.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyglet\n",
            "  Downloading pyglet-2.0.0-py3-none-any.whl (966 kB)\n",
            "\u001b[K     |████████████████████████████████| 966 kB 4.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: pyglet\n",
            "Successfully installed pyglet-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import base64\n",
        "import imageio\n",
        "import IPython\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import PIL.Image\n",
        "import pyvirtualdisplay\n",
        "import reverb\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tf_agents.agents.dqn import dqn_agent\n",
        "from tf_agents.drivers import py_driver\n",
        "from tf_agents.environments import suite_gym\n",
        "from tf_agents.environments import tf_py_environment\n",
        "from tf_agents.eval import metric_utils\n",
        "from tf_agents.metrics import tf_metrics\n",
        "from tf_agents.networks import sequential\n",
        "from tf_agents.policies import py_tf_eager_policy\n",
        "from tf_agents.policies import random_tf_policy\n",
        "from tf_agents.replay_buffers import reverb_replay_buffer\n",
        "from tf_agents.replay_buffers import reverb_utils\n",
        "from tf_agents.trajectories import trajectory\n",
        "from tf_agents.specs import tensor_spec\n",
        "from tf_agents.utils import common"
      ],
      "metadata": {
        "id": "hiX7OCh0uVdV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gym setup"
      ],
      "metadata": {
        "id": "31tTx_F4vYSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"gym>=0.21.0\""
      ],
      "metadata": {
        "id": "NiYkYlGfvbxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import abc\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "\n",
        "from tf_agents.environments import py_environment\n",
        "from tf_agents.environments import tf_environment\n",
        "from tf_agents.environments import tf_py_environment\n",
        "from tf_agents.environments import utils\n",
        "from tf_agents.specs import array_spec\n",
        "from tf_agents.environments import wrappers\n",
        "from tf_agents.environments import suite_gym\n",
        "from tf_agents.trajectories import time_step as ts"
      ],
      "metadata": {
        "id": "xVskUfdZveqt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "282713a4-47da-42f2-87a7-40c12f3ca182"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-3382b3a2f80a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_agents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvironments\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpy_environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_agents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvironments\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf_environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_agents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvironments\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf_py_environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tf_agents/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_agents\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0magents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_agents\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbandits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_agents\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tf_agents/agents/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\"\"\"Module importing all agents.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_agents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbehavioral_cloning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_agents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcategorical_dqn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_agents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcql\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tf_agents/agents/behavioral_cloning/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\"\"\"A Behavioral Cloning agent.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_agents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbehavioral_cloning\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbehavioral_cloning_agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tf_agents/agents/behavioral_cloning/behavioral_cloning_agent.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_probability\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_agents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_converter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_agents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf_agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_agents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdistribution_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tf_agents/agents/data_converter.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_agents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_agents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrajectories\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpolicy_step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_agents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrajectories\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime_step\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_agents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrajectories\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrajectory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tf_agents/trajectories/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_agents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrajectories\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpolicy_step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_agents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrajectories\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime_step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_agents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrajectories\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrajectory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_agents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrajectories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy_step\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPolicyInfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tf_agents/trajectories/trajectory.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_agents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrajectories\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime_step\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_agents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_agents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcomposite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_agents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnest_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_agents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvalue_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tf_agents/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_agents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlazy_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_agents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnest_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_agents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy_storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_agents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msession_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_agents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_normalizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tf_agents/utils/numpy_storage.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# pylint:disable=g-direct-tensorflow-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrackable\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase\u001b[0m  \u001b[0;31m# TF internal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrackable\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_structures\u001b[0m  \u001b[0;31m# TF internal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;31m# pylint:enable=g-direct-tensorflow-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/trackable/data_structures.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0mmin_producer_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mmin_consumer_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1113\u001b[0;31m         setter=operator.setitem)])\n\u001b[0m\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/revived_types.py\u001b[0m in \u001b[0;36mregister_revived_type\u001b[0;34m(identifier, predicate, versions)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0midentifier\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_REVIVED_TYPE_REGISTRY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Duplicate registrations for type '{identifier}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m   \u001b[0m_REVIVED_TYPE_REGISTRY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Duplicate registrations for type 'trackable_dict_wrapper'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Wordle Data Setup"
      ],
      "metadata": {
        "id": "5qx2BXGMmaza"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import io\n",
        "\n",
        "import urllib.request\n",
        "import os\n",
        "from os import path"
      ],
      "metadata": {
        "id": "Asrp22bjzJGV"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data_source = \"https://raw.githubusercontent.com/tabatkins/wordle-list/main/words\"\n",
        "directory_name = \"WordleData\"\n",
        "file_name = \"wordList.txt\"\n",
        "\n",
        "\n",
        "def retrieve_data():\n",
        "    url_request = urllib.request.urlopen(raw_data_source)\n",
        "    data = url_request.read().decode(\"utf-8\")\n",
        "    return data\n",
        "\n",
        "\n",
        "def store_data():\n",
        "    if os.path.isfile(get_file_path()) == False:\n",
        "        data = retrieve_data()\n",
        "        os.mkdir(directory_name)\n",
        "        file = open(get_file_path(), \"w\")\n",
        "        file.write(data)\n",
        "        file.close\n",
        "\n",
        "\n",
        "def get_file_path():\n",
        "    return path.join(directory_name, file_name)\n"
      ],
      "metadata": {
        "id": "zSCOnRf4mfwS"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_data()\n",
        "\n",
        "find_word = {}\n",
        "find_num = {}\n",
        "\n",
        "with open(get_file_path()) as f:\n",
        "  words = f.read().splitlines()\n",
        "\n",
        "for i in range(len(words)):\n",
        "  find_word[i] = words[i]\n",
        "  find_num[words[i]] = i\n",
        "\n",
        "num_words = len(find_word)\n",
        "num_words"
      ],
      "metadata": {
        "id": "lqcyaYfAzLOi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6a33074-dcc3-408a-d4e5-9cf56dd48ad2"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14855"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Environment\n",
        "Based on https://www.tensorflow.org/agents/tutorials/2_environments_tutorial#creating_your_own_python_environment"
      ],
      "metadata": {
        "id": "JKfdj7qZvBMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wordle_rows = 6 # @param {type:\"integer\"}\n",
        "wordle_cols = 5  # @param {type:\"integer\"}\n",
        "wordle_colors = 3  # @param {type:\"integer\"}\n",
        "\n",
        "english_letters = 26  # @param {type:\"integer\"}"
      ],
      "metadata": {
        "id": "wyA-fOYTpufe"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def get_observation_array(game):\n",
        "  obs = np.zeros((wordle_rows * wordle_cols, english_letters, wordle_colors), dtype=np.int32)\n",
        "  # for every tile on the board\n",
        "  for row in range(len(game.board)):\n",
        "    for col in range(len(game.board[row])):\n",
        "      char = game.board[row][col].char\n",
        "      color = game.board[row][col].color\n",
        "      obs[row * 5 + col,ord(char) - 65,int(color)] = 1\n",
        "\n",
        "  return obs\n",
        "\n",
        "def get_reward(game):\n",
        "  sum = 0\n",
        "  # for row in game.board:\n",
        "  #   for tile in row:\n",
        "  #     sum += int(tile.color) + 1\n",
        "  # for row in game.board:\n",
        "  if len(game.board) == 0: return 0\n",
        "  for tile in game.board[len(game.board) - 1]:\n",
        "    sum += int(tile.color) + 1\n",
        "  return sum\n",
        "  # return np.array([sum], dtype=np.int32)"
      ],
      "metadata": {
        "id": "FNOPczmKojWq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WordleEnvironment(py_environment.PyEnvironment):\n",
        "  def __init__(self):\n",
        "    self._action_spec = array_spec.BoundedArraySpec(\n",
        "        shape=(), dtype=np.int32, minimum=0, maximum=num_words - 1, name='action'\n",
        "    )\n",
        "    self._observation_spec = array_spec.BoundedArraySpec(\n",
        "        shape=(wordle_rows * wordle_cols, english_letters, wordle_colors), dtype=np.int32, minimum=0, maximum=1, name='observation'\n",
        "    )\n",
        "    \n",
        "    self.game = WordleGame(find_word[random.randint(0,num_words)])\n",
        "\n",
        "  def action_spec(self):\n",
        "    return self._action_spec\n",
        "  \n",
        "  def observation_spec(self):\n",
        "    return self._observation_spec\n",
        "  \n",
        "  def _reset(self):\n",
        "    self.game = WordleGame(find_word[random.randint(0,num_words)])\n",
        "    return ts.restart(get_observation_array(self.game)) # TODO update\n",
        "\n",
        "  def _step(self, action):\n",
        "    debug(\"stepped\")\n",
        "    debug(\"ACTION:\", int(action))\n",
        "    if self.game.is_over: \n",
        "      debug(\"resetting\")\n",
        "      return self.reset()\n",
        "\n",
        "    # perform the action \n",
        "    colors = self.game.guess(find_word[int(action)])\n",
        "\n",
        "    # return the observation state\n",
        "    # if the game is now over\n",
        "    if self.game.is_over:\n",
        "      debug(\"terminating\")\n",
        "      return ts.termination(get_observation_array(self.game), reward=get_reward(self.game))\n",
        "    \n",
        "    return ts.transition(get_observation_array(self.game), reward=get_reward(self.game), discount=1.0)\n",
        "\n",
        "  def _current_time_step(self):\n",
        "    return len(self.game.board)"
      ],
      "metadata": {
        "id": "RhzLi53QvEIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### test the environment"
      ],
      "metadata": {
        "id": "xqNWJeOt15af"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "testing_env = WordleEnvironment()\n",
        "time_step = testing_env.reset()\n",
        "# print(time_step)\n",
        "while not time_step.is_last():\n",
        "  time_step = testing_env.step(np.array(random.randint(0, num_words), dtype=np.int32))\n",
        "  print(time_step)"
      ],
      "metadata": {
        "id": "spm0pJV9nnY7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a79c5b2f-352b-48a8-de1b-cced75fc8e24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TimeStep(\n",
            "{'discount': array(1., dtype=float32),\n",
            " 'observation': array([[[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]]], dtype=int32),\n",
            " 'reward': array(7., dtype=float32),\n",
            " 'step_type': array(1, dtype=int32)})\n",
            "TimeStep(\n",
            "{'discount': array(1., dtype=float32),\n",
            " 'observation': array([[[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]]], dtype=int32),\n",
            " 'reward': array(6., dtype=float32),\n",
            " 'step_type': array(1, dtype=int32)})\n",
            "TimeStep(\n",
            "{'discount': array(1., dtype=float32),\n",
            " 'observation': array([[[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]]], dtype=int32),\n",
            " 'reward': array(5., dtype=float32),\n",
            " 'step_type': array(1, dtype=int32)})\n",
            "TimeStep(\n",
            "{'discount': array(1., dtype=float32),\n",
            " 'observation': array([[[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]]], dtype=int32),\n",
            " 'reward': array(8., dtype=float32),\n",
            " 'step_type': array(1, dtype=int32)})\n",
            "TimeStep(\n",
            "{'discount': array(1., dtype=float32),\n",
            " 'observation': array([[[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]]], dtype=int32),\n",
            " 'reward': array(5., dtype=float32),\n",
            " 'step_type': array(1, dtype=int32)})\n",
            "TimeStep(\n",
            "{'discount': array(0., dtype=float32),\n",
            " 'observation': array([[[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[0, 1, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       [[1, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]]], dtype=int32),\n",
            " 'reward': array(8., dtype=float32),\n",
            " 'step_type': array(2, dtype=int32)})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test the observation spec\n",
        "game = WordleGame(find_word[random.randint(0,num_words)])\n",
        "game.guess(\"LATER\")\n",
        "print(\"Answer: \", game.answer)\n",
        "obs = get_observation_array(game)\n",
        "print(\"Tile 0 [L]: \", obs[0][ord(\"L\")-65])\n",
        "print(\"Tile 1 [A]: \", obs[1][ord(\"A\")-65])\n",
        "print(\"Tile 2 [T]: \", obs[2][ord(\"T\")-65])\n",
        "print(\"Tile 3 [E]: \", obs[3][ord(\"E\")-65])\n",
        "print(\"Tile 4 [R]: \", obs[4][ord(\"R\")-65])\n",
        "\n",
        "print(\"Current reward:\", get_reward(game))"
      ],
      "metadata": {
        "id": "j-wHZ7rW14qz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a28c48fa-e194-460b-e76d-2d2dd41fcf79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer:  MEIDS\n",
            "Tile 0 [L]:  [1 0 0]\n",
            "Tile 1 [A]:  [1 0 0]\n",
            "Tile 2 [T]:  [1 0 0]\n",
            "Tile 3 [E]:  [0 1 0]\n",
            "Tile 4 [R]:  [1 0 0]\n",
            "Current reward: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Convert to TF Environment"
      ],
      "metadata": {
        "id": "uDeC5XPVul8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf_env = tf_py_environment.TFPyEnvironment(WordleEnvironment())\n",
        "\n",
        "print(isinstance(tf_env, tf_environment.TFEnvironment))\n",
        "print(\"TimeStep Specs:\", tf_env.time_step_spec())\n",
        "print(\"Action Specs:\", tf_env.action_spec())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rfw8qG6IulnR",
        "outputId": "3e369930-35f4-4c96-f551-1583cbdd3daa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "TimeStep Specs: TimeStep(\n",
            "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
            " 'observation': BoundedTensorSpec(shape=(30, 26, 3), dtype=tf.int32, name='observation', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32)),\n",
            " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
            " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})\n",
            "Action Specs: BoundedTensorSpec(shape=(), dtype=tf.int32, name='action', minimum=array(0, dtype=int32), maximum=array(14854, dtype=int32))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "tJDh45LJx8ys"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### training parameters"
      ],
      "metadata": {
        "id": "Cqq5wHghzbXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_iterations = 20000 # @param {type:\"integer\"}\n",
        "\n",
        "initial_collect_steps = 100  # @param {type:\"integer\"}\n",
        "collect_steps_per_iteration =   1# @param {type:\"integer\"}\n",
        "replay_buffer_max_length = 100000  # @param {type:\"integer\"}\n",
        "\n",
        "batch_size = 64  # @param {type:\"integer\"}\n",
        "learning_rate = 1e-3  # @param {type:\"number\"}\n",
        "log_interval = 1000  # @param {type:\"integer\"}\n",
        "\n",
        "num_eval_episodes = 10  # @param {type:\"integer\"}\n",
        "eval_interval = 200  # @param {type:\"integer\"}"
      ],
      "metadata": {
        "id": "lP0HMMuG1_9l",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert to TF Environment\n",
        "train_py_env = WordleEnvironment()\n",
        "eval_py_env = WordleEnvironment()\n",
        "\n",
        "train_env = tf_py_environment.TFPyEnvironment(train_py_env)\n",
        "eval_env = tf_py_environment.TFPyEnvironment(eval_py_env)\n"
      ],
      "metadata": {
        "id": "K6C5EIG_6Cpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### training debug info"
      ],
      "metadata": {
        "id": "movIhlKH6C9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Observation Spec:')\n",
        "print(train_py_env.time_step_spec().observation)\n",
        "print('Reward Spec:')\n",
        "print(train_py_env.time_step_spec().reward)\n",
        "print('Action Spec:')\n",
        "print(train_py_env.action_spec())\n",
        "\n",
        "print('action_spec:', train_py_env.action_spec())\n",
        "print('time_step_spec.observation:', train_py_env.time_step_spec().observation)\n",
        "print('time_step_spec.step_type:', train_py_env.time_step_spec().step_type)\n",
        "print('time_step_spec.discount:', train_py_env.time_step_spec().discount)\n",
        "print('time_step_spec.reward:', train_py_env.time_step_spec().reward)\n"
      ],
      "metadata": {
        "id": "x8Zj-Wdrx_Mv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a1c59ec-6395-4686-9e39-a76ab6f36f94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Observation Spec:\n",
            "BoundedArraySpec(shape=(30, 26, 3), dtype=dtype('int32'), name='observation', minimum=0, maximum=1)\n",
            "Reward Spec:\n",
            "ArraySpec(shape=(), dtype=dtype('float32'), name='reward')\n",
            "Action Spec:\n",
            "BoundedArraySpec(shape=(), dtype=dtype('int32'), name='action', minimum=0, maximum=14854)\n",
            "action_spec: BoundedArraySpec(shape=(), dtype=dtype('int32'), name='action', minimum=0, maximum=14854)\n",
            "time_step_spec.observation: BoundedArraySpec(shape=(30, 26, 3), dtype=dtype('int32'), name='observation', minimum=0, maximum=1)\n",
            "time_step_spec.step_type: ArraySpec(shape=(), dtype=dtype('int32'), name='step_type')\n",
            "time_step_spec.discount: BoundedArraySpec(shape=(), dtype=dtype('float32'), name='discount', minimum=0.0, maximum=1.0)\n",
            "time_step_spec.reward: ArraySpec(shape=(), dtype=dtype('float32'), name='reward')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Observation Spec:')\n",
        "print(eval_py_env.time_step_spec().observation)\n",
        "print('Reward Spec:')\n",
        "print(eval_py_env.time_step_spec().reward)\n",
        "print('Action Spec:')\n",
        "print(eval_py_env.action_spec())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-jJHeWpQVDs",
        "outputId": "b20ac915-8545-472d-ed94-417ffcf32afa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Observation Spec:\n",
            "BoundedArraySpec(shape=(30, 26, 3), dtype=dtype('int32'), name='observation', minimum=0, maximum=1)\n",
            "Reward Spec:\n",
            "ArraySpec(shape=(), dtype=dtype('float32'), name='reward')\n",
            "Action Spec:\n",
            "BoundedArraySpec(shape=(), dtype=dtype('int32'), name='action', minimum=0, maximum=14854)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zf6KNHHPD_yF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Agent"
      ],
      "metadata": {
        "id": "B7IvK9aVTcgm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer_params = (100, 50)\n",
        "action_tensor_spec = tensor_spec.from_spec(train_env.action_spec())\n",
        "num_actions = action_tensor_spec.maximum - action_tensor_spec.minimum + 1\n",
        "num_actions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poxG_R5PTi5M",
        "outputId": "eae684a4-9b30-4037-c449-b1c81d3e760d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14855"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# helper method for creating a bunch of dense layers\n",
        "def make_dense_layer(units):\n",
        "  return tf.keras.layers.Dense(\n",
        "      units,\n",
        "      activation=tf.keras.activations.relu,\n",
        "      kernel_initializer=tf.keras.initializers.VarianceScaling(\n",
        "          scale=2.0, mode='fan_in', distribution='truncated_normal'\n",
        "      )\n",
        "  )t\n",
        "\n",
        "# create DQN \n",
        "dense_layers = [make_dense_layer(units) for units in layer_params]\n",
        "q_vals_layer = tf.keras.layers.Dense(\n",
        "    num_actions,\n",
        "    activation=None,\n",
        "    kernel_initializer=tf.keras.initializers.RandomUniform(\n",
        "        minval=-0.03, maxval=0.03\n",
        "    ),\n",
        "    bias_initializer=tf.keras.initializers.Constant(-0.2)\n",
        ")\n",
        "\n",
        "q_net = sequential.Sequential([tf.keras.layers.Flatten()] + dense_layers + [q_vals_layer])"
      ],
      "metadata": {
        "id": "rA6fQQxSTu52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "train_step_counter = tf.Variable(0)\n",
        "\n",
        "agent = dqn_agent.DqnAgent(\n",
        "    train_env.time_step_spec(),\n",
        "    train_env.action_spec(),\n",
        "    q_network=q_net,\n",
        "    optimizer=optimizer,\n",
        "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
        "    train_step_counter=train_step_counter\n",
        ")\n",
        "\n",
        "agent.initialize()"
      ],
      "metadata": {
        "id": "Ja2G8rUSaBLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Policies"
      ],
      "metadata": {
        "id": "NydZm8NMtiYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_policy = agent.policy\n",
        "collect_policy = agent.collect_policy"
      ],
      "metadata": {
        "id": "HOxreySStjuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### random policy"
      ],
      "metadata": {
        "id": "C7ywoOwa31P9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_policy = random_tf_policy.RandomTFPolicy(train_env.time_step_spec(),\n",
        "                                                train_env.action_spec())\n",
        "eval_policy = agent.policy\n",
        "collect_policy = agent.collect_policy\n",
        "\n",
        "train_env.time_step_spec().observation.shape, train_env.time_step_spec().observation.shape, random_policy.time_step_spec.observation.shape\n",
        "\n",
        "time2 = train_env.reset()\n",
        "# train_env.time_step_spec().observation.shape, train_env.time_step_spec().observation.shape, random_policy.time_step_spec.observation.shape\n",
        "\n",
        "random_policy.action(time2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YDLWLOy30Wm",
        "outputId": "196d7fd3-654d-4de1-ec50-96b3fd0bb967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([9813], dtype=int32)>, state=(), info=())"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Metrics & Evaluaion"
      ],
      "metadata": {
        "id": "FWz6FToS36eC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_avg_return(environment, policy, num_episodes=10):\n",
        "  total_return = 0.0\n",
        "  for _ in range(num_episodes):\n",
        "    time_step = environment.reset()\n",
        "    episode_return = 0.0\n",
        "\n",
        "    while not time_step.is_last():\n",
        "      action_step = policy.action(time_step)\n",
        "      time_step = environment.step(action_step.action)\n",
        "      episode_return += time_step.reward\n",
        "    total_return += episode_return\n",
        "  avg_return = total_return / num_episodes\n",
        "  return avg_return.numpy()[0]"
      ],
      "metadata": {
        "id": "qABN7MAl39nZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### test metrics"
      ],
      "metadata": {
        "id": "mMljKoIs5Sb2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compute_avg_return(eval_env, random_policy, num_eval_episodes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6reWqmJ5Rsd",
        "outputId": "52eac319-5fed-457b-86d7-675277482d81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38.7"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Replay Buffer"
      ],
      "metadata": {
        "id": "uztQAqeA-Z6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "table_name = 'uniform_table'\n",
        "replay_buffer_signature = tensor_spec.from_spec(agent.collect_data_spec)\n",
        "replay_buffer_signature = tensor_spec.add_outer_dim(replay_buffer_signature)\n",
        "\n",
        "table = reverb.Table(\n",
        "    table_name,\n",
        "    max_size = replay_buffer_max_length,\n",
        "    sampler = reverb.selectors.Uniform(),\n",
        "    remover = reverb.selectors.Fifo(),\n",
        "    rate_limiter = reverb.rate_limiters.MinSize(1),\n",
        "    signature = replay_buffer_signature\n",
        ")\n",
        "\n",
        "reverb_server = reverb.Server([table])\n",
        "\n",
        "replay_buffer = reverb_replay_buffer.ReverbReplayBuffer(\n",
        "    agent.collect_data_spec,\n",
        "    table_name = table_name,\n",
        "    sequence_length = 2,\n",
        "    local_server = reverb_server\n",
        ")\n",
        "\n",
        "rb_observer = reverb_utils.ReverbAddTrajectoryObserver(\n",
        "    replay_buffer.py_client,\n",
        "    table_name,\n",
        "    sequence_length=2\n",
        ")"
      ],
      "metadata": {
        "id": "3XGIDchy-iMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Collection"
      ],
      "metadata": {
        "id": "8dWvwb0WBODG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = WordleEnvironment()\n",
        "py_driver.PyDriver(\n",
        "    env,\n",
        "    py_tf_eager_policy.PyTFEagerPolicy(\n",
        "        random_policy, use_tf_function=True\n",
        "    ),\n",
        "    [rb_observer],\n",
        "    max_steps=initial_collect_steps\n",
        ").run(train_py_env.reset())"
      ],
      "metadata": {
        "id": "eQFNhgIGBVpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = replay_buffer.as_dataset(\n",
        "    num_parallel_calls = 3,\n",
        "    sample_batch_size = batch_size,\n",
        "    num_steps = 2\n",
        ").prefetch(3)\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "id": "V6Jwuq9uFPs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iterator = iter(dataset)\n",
        "print(iterator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwGUWbDiFZcQ",
        "outputId": "2f07f3fc-8593-4694-b2e7-99202678cdee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7f3be20f2610>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the agent!"
      ],
      "metadata": {
        "id": "viLJmeqjFfdi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try: \n",
        "  %% time\n",
        "except:\n",
        "  pass\n",
        "\n",
        "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
        "agent.train = common.function(agent.train)\n",
        "\n",
        "# reset train step\n",
        "agent.train_step_counter.assign(0)\n",
        "\n",
        "# eval agent's policy once before training\n",
        "avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
        "returns = [avg_return]\n",
        "\n",
        "# reset environment\n",
        "time_step = train_py_env.reset()\n",
        "\n",
        "# create a driver to collect experience\n",
        "collect_driver = py_driver.PyDriver(\n",
        "    env,\n",
        "    py_tf_eager_policy.PyTFEagerPolicy(\n",
        "        agent.collect_policy, use_tf_function=True\n",
        "    ),\n",
        "    [rb_observer],\n",
        "    max_steps=collect_steps_per_iteration\n",
        ")\n",
        "\n",
        "# train!\n",
        "for _ in range(num_iterations):\n",
        "  # collect some steps to save into replay buffer\n",
        "  time_step, _ = collect_driver.run(time_step)\n",
        "\n",
        "  #sample a batch of data from the buffer, update the agent's network\n",
        "  experience, unused_info = next(iterator)\n",
        "  train_loss = agent.train(experience).loss\n",
        "  \n",
        "  step = agent.train_step_counter.numpy()\n",
        "\n",
        "  if step % log_interval == 0:\n",
        "    print(\"step = {0}: loss = {1}\".format(step, train_loss))\n",
        "\n",
        "  if step % eval_interval == 0:\n",
        "    avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
        "    print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
        "    returns.append(avg_return)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwkZjwnJFgtO",
        "outputId": "45e5f251-b312-4113-87da-c5ada138f89d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.foldr(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 200: Average Return = 45.0\n",
            "step = 400: Average Return = 34.79999923706055\n",
            "step = 600: Average Return = 46.20000076293945\n",
            "step = 800: Average Return = 44.400001525878906\n",
            "step = 1000: loss = 228698608.0\n",
            "step = 1000: Average Return = 33.0\n",
            "step = 1200: Average Return = 38.400001525878906\n",
            "step = 1400: Average Return = 40.20000076293945\n",
            "step = 1600: Average Return = 37.79999923706055\n",
            "step = 1800: Average Return = 34.20000076293945\n",
            "step = 2000: loss = 55566608.0\n",
            "step = 2000: Average Return = 41.400001525878906\n",
            "step = 2200: Average Return = 39.599998474121094\n",
            "step = 2400: Average Return = 45.599998474121094\n",
            "step = 2600: Average Return = 33.599998474121094\n",
            "step = 2800: Average Return = 41.400001525878906\n",
            "step = 3000: loss = 13758900.0\n",
            "step = 3000: Average Return = 36.0\n",
            "step = 3200: Average Return = 36.599998474121094\n",
            "step = 3400: Average Return = 40.5\n",
            "step = 3600: Average Return = 37.20000076293945\n",
            "step = 3800: Average Return = 42.400001525878906\n",
            "step = 4000: loss = 5923324.0\n",
            "step = 4000: Average Return = 41.79999923706055\n",
            "step = 4200: Average Return = 37.20000076293945\n",
            "step = 4400: Average Return = 39.599998474121094\n",
            "step = 4600: Average Return = 43.099998474121094\n",
            "step = 4800: Average Return = 43.79999923706055\n",
            "step = 5000: loss = 980487.3125\n",
            "step = 5000: Average Return = 40.79999923706055\n",
            "step = 5200: Average Return = 42.099998474121094\n",
            "step = 5400: Average Return = 36.5\n",
            "step = 5600: Average Return = 37.20000076293945\n",
            "step = 5800: Average Return = 39.20000076293945\n",
            "step = 6000: loss = 389129.75\n",
            "step = 6000: Average Return = 44.099998474121094\n",
            "step = 6200: Average Return = 42.20000076293945\n",
            "step = 6400: Average Return = 39.599998474121094\n",
            "step = 6600: Average Return = 43.599998474121094\n",
            "step = 6800: Average Return = 40.599998474121094\n",
            "step = 7000: loss = 298161.0\n",
            "step = 7000: Average Return = 42.900001525878906\n",
            "step = 7200: Average Return = 43.400001525878906\n",
            "step = 7400: Average Return = 43.29999923706055\n",
            "step = 7600: Average Return = 39.900001525878906\n",
            "step = 7800: Average Return = 41.900001525878906\n",
            "step = 8000: loss = 59087.203125\n",
            "step = 8000: Average Return = 39.599998474121094\n",
            "step = 8200: Average Return = 43.400001525878906\n",
            "step = 8400: Average Return = 40.5\n",
            "step = 8600: Average Return = 43.20000076293945\n",
            "step = 8800: Average Return = 37.5\n",
            "step = 9000: loss = 17625.8359375\n",
            "step = 9000: Average Return = 37.29999923706055\n",
            "step = 9200: Average Return = 43.29999923706055\n",
            "step = 9400: Average Return = 40.79999923706055\n",
            "step = 9600: Average Return = 43.29999923706055\n",
            "step = 9800: Average Return = 40.099998474121094\n",
            "step = 10000: loss = 33816.30859375\n",
            "step = 10000: Average Return = 40.70000076293945\n",
            "step = 10200: Average Return = 39.20000076293945\n",
            "step = 10400: Average Return = 41.20000076293945\n",
            "step = 10600: Average Return = 39.599998474121094\n",
            "step = 10800: Average Return = 40.599998474121094\n",
            "step = 11000: loss = 115.21701049804688\n",
            "step = 11000: Average Return = 42.0\n",
            "step = 11200: Average Return = 40.599998474121094\n",
            "step = 11400: Average Return = 39.099998474121094\n",
            "step = 11600: Average Return = 39.400001525878906\n",
            "step = 11800: Average Return = 42.599998474121094\n",
            "step = 12000: loss = 2279.320068359375\n",
            "step = 12000: Average Return = 42.0\n",
            "step = 12200: Average Return = 42.0\n",
            "step = 12400: Average Return = 44.400001525878906\n",
            "step = 12600: Average Return = 34.79999923706055\n",
            "step = 12800: Average Return = 42.0\n",
            "step = 13000: loss = 64.09312438964844\n",
            "step = 13000: Average Return = 42.0\n",
            "step = 13200: Average Return = 41.400001525878906\n",
            "step = 13400: Average Return = 39.599998474121094\n",
            "step = 13600: Average Return = 36.599998474121094\n",
            "step = 13800: Average Return = 42.599998474121094\n",
            "step = 14000: loss = 1382.489013671875\n",
            "step = 14000: Average Return = 39.0\n",
            "step = 14200: Average Return = 39.0\n",
            "step = 14400: Average Return = 40.20000076293945\n",
            "step = 14600: Average Return = 41.400001525878906\n",
            "step = 14800: Average Return = 42.599998474121094\n",
            "step = 15000: loss = 79.67552185058594\n",
            "step = 15000: Average Return = 40.79999923706055\n",
            "step = 15200: Average Return = 39.599998474121094\n",
            "step = 15400: Average Return = 41.400001525878906\n",
            "step = 15600: Average Return = 37.79999923706055\n",
            "step = 15800: Average Return = 37.79999923706055\n",
            "step = 16000: loss = 91.25132751464844\n",
            "step = 16000: Average Return = 45.0\n",
            "step = 16200: Average Return = 43.79999923706055\n",
            "step = 16400: Average Return = 40.79999923706055\n",
            "step = 16600: Average Return = 39.599998474121094\n",
            "step = 16800: Average Return = 40.79999923706055\n",
            "step = 17000: loss = 106.56315612792969\n",
            "step = 17000: Average Return = 41.400001525878906\n",
            "step = 17200: Average Return = 41.400001525878906\n",
            "step = 17400: Average Return = 45.599998474121094\n",
            "step = 17600: Average Return = 36.0\n",
            "step = 17800: Average Return = 40.20000076293945\n",
            "step = 18000: loss = 94.83834075927734\n",
            "step = 18000: Average Return = 41.400001525878906\n",
            "step = 18200: Average Return = 42.599998474121094\n",
            "step = 18400: Average Return = 40.20000076293945\n",
            "step = 18600: Average Return = 37.79999923706055\n",
            "step = 18800: Average Return = 40.79999923706055\n",
            "step = 19000: loss = 96.8173828125\n",
            "step = 19000: Average Return = 43.20000076293945\n",
            "step = 19200: Average Return = 41.400001525878906\n",
            "step = 19400: Average Return = 41.29999923706055\n",
            "step = 19600: Average Return = 40.5\n",
            "step = 19800: Average Return = 42.0\n",
            "step = 20000: loss = 56.78323745727539\n",
            "step = 20000: Average Return = 42.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iterations = range(0, num_iterations + 1, eval_interval)\n",
        "plt.plot(iterations, returns)\n",
        "plt.ylabel('Average Return')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylim(top=250)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "OShvrWDFzHyh",
        "outputId": "7af80353-51d7-41fe-8bf4-4ca8b8cb613b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32.339999961853025, 250.0)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Manual Test"
      ],
      "metadata": {
        "id": "ZJM6hidh1KK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "custom_env = WordleEnvironment()\n",
        "custom_env.game = WordleGame(\"HELLO\");\n",
        "\n",
        "print(\"Game word  : HELLO\")\n",
        "print(\"Init reward:\", get_reward(custom_env.game))\n",
        "\n",
        "# 2693 = HELPS\n",
        "helps = custom_env.step(np.array([2693], dtype=np.int32));\n",
        "\n",
        "print(\"Reward after HELPS:\", get_reward(custom_env.game))\n",
        "\n",
        "\n",
        "next_number = np.array(agent.policy.action(time2).action)[0]\n",
        "next_word = find_word[next_number]\n",
        "# next_word = 'hello'\n",
        "# next_number = find_num[next_word]\n",
        "print(\"next word:\", next_word)\n",
        "\n",
        "\n",
        "helps = custom_env.step(np.array([next_number], dtype=np.int32));\n",
        "\n",
        "print(get_reward(custom_env.game))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frXmVCZi1Jkt",
        "outputId": "e824748b-fbd4-45db-fba1-1afa7ce3ac78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Game word  : HELLO\n",
            "Init reward: 0\n",
            "Reward after HELPS: 11\n",
            "next word: jiaos\n",
            "6\n"
          ]
        }
      ]
    }
  ]
}